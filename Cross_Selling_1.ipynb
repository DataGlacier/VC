{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0e7307-4e82-4193-8116-c443c1a07203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kuzmauchiha\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "working_directory = os.getcwd()\n",
    "print(working_directory)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8bcdb-4558-44e2-8ea4-b452327fb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mq/vcvt6mq97_g4g_xrl4khtv4w0000gn/T/ipykernel_19979/2715705207.py:20: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_bonus = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year Range Counts:\n",
      "1995-2000: 0\n",
      "2001-2012: 0\n",
      "2013-2018: 929615\n",
      "\n",
      "Oldest Year in 'year': 2016\n",
      "Newest Year in 'year': 2016\n",
      "\n",
      "Common Province Names in 'nomprov' Column:\n",
      "nomprov\n",
      "MADRID                    298250\n",
      "BARCELONA                  88579\n",
      "VALENCIA                   47996\n",
      "SEVILLA                    40492\n",
      "CORUÃ‘A, A                  28715\n",
      "MURCIA                     27752\n",
      "MALAGA                     24546\n",
      "ZARAGOZA                   23160\n",
      "ALICANTE                   22147\n",
      "CADIZ                      19795\n",
      "PONTEVEDRA                 18961\n",
      "ASTURIAS                   18300\n",
      "PALMAS, LAS                16332\n",
      "VALLADOLID                 16018\n",
      "BADAJOZ                    12936\n",
      "TOLEDO                     12658\n",
      "BIZKAIA                    12494\n",
      "GRANADA                    12392\n",
      "SALAMANCA                  11071\n",
      "CANTABRIA                  10824\n",
      "CORDOBA                     9831\n",
      "BALEARS, ILLES              9130\n",
      "CACERES                     8598\n",
      "CIUDAD REAL                 8075\n",
      "HUELVA                      8018\n",
      "ALBACETE                    7780\n",
      "TARRAGONA                   7631\n",
      "CASTELLON                   7145\n",
      "BURGOS                      6645\n",
      "GIRONA                      6304\n",
      "NAVARRA                     6010\n",
      "RIOJA, LA                   5806\n",
      "LEON                        5717\n",
      "LUGO                        5656\n",
      "OURENSE                     5605\n",
      "LERIDA                      5430\n",
      "SANTA CRUZ DE TENERIFE      5097\n",
      "GIPUZKOA                    4869\n",
      "GUADALAJARA                 4678\n",
      "JAEN                        4496\n",
      "ALMERIA                     4307\n",
      "CUENCA                      3788\n",
      "ZAMORA                      3430\n",
      "PALENCIA                    3311\n",
      "SEGOVIA                     2881\n",
      "HUESCA                      2789\n",
      "AVILA                       2628\n",
      "ALAVA                       2591\n",
      "TERUEL                      1538\n",
      "SORIA                       1261\n",
      "MELILLA                      643\n",
      "CEUTA                        513\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to 'Test.csv'\n",
    "path = working_directory + '/Downloads/Cross-Selling/Test.csv'\n",
    "\n",
    "# Get the file size in bytes\n",
    "file_size_bytes = os.path.getsize(path)\n",
    "\n",
    "# Convert file size to a human-readable format (e.g., KB, MB, GB)\n",
    "def convert_bytes(byte_size):\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if byte_size < 1024.0:\n",
    "            return f\"{byte_size:.2f} {unit}\"\n",
    "        byte_size /= 1024.0\n",
    "\n",
    "file_size_readable = convert_bytes(file_size_bytes)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_bonus = pd.read_csv(path)\n",
    "\n",
    "# Data exploration code (Age, Canal_Entrada, Ind_Nuevo, Sexo, etc.)\n",
    "\n",
    "# Convert 'fecha_dato' to a datetime data type\n",
    "df_bonus['fecha_dato'] = pd.to_datetime(df_bonus['fecha_dato'])\n",
    "\n",
    "# Extract the year from 'fecha_dato' and store it as a new column\n",
    "df_bonus['year'] = df_bonus['fecha_dato'].dt.year\n",
    "\n",
    "# Create year ranges based on the new 'year' column\n",
    "year_ranges = [(1995, 2000), (2001, 2012), (2013, 2018)]\n",
    "\n",
    "# Initialize a dictionary to store counts for each year range\n",
    "year_range_counts = {f\"{start}-{end}\": 0 for start, end in year_ranges}\n",
    "\n",
    "# Extract the year from the 'year' column and count occurrences in each year range\n",
    "for start, end in year_ranges:\n",
    "    year_range_counts[f\"{start}-{end}\"] = len(df_bonus[(df_bonus['year'] >= start) & (df_bonus['year'] <= end)])\n",
    "\n",
    "# Display the counts for each year range\n",
    "print(\"\\nYear Range Counts:\")\n",
    "for year_range, count in year_range_counts.items():\n",
    "    print(f\"{year_range}: {count}\")\n",
    "\n",
    "# Find the oldest and newest year in the 'year' column\n",
    "oldest_year = df_bonus['year'].min()\n",
    "newest_year = df_bonus['year'].max()\n",
    "\n",
    "print(f\"\\nOldest Year in 'year': {oldest_year}\")\n",
    "print(f\"Newest Year in 'year': {newest_year}\")\n",
    "\n",
    "# Count and display common province names in the 'nomprov' column\n",
    "province_counts = df_bonus['nomprov'].value_counts()\n",
    "\n",
    "print(\"\\nCommon Province Names in 'nomprov' Column:\")\n",
    "print(province_counts)\n",
    "\n",
    "# Machine learning code\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define 'X' (feature matrix) and 'y' (target variable)\n",
    "# Exclude non-numeric columns and any other columns that should not be used as features\n",
    "exclude_columns = ['antiguedad', 'fecha_dato', 'year']\n",
    "X = df_bonus.drop(exclude_columns, axis=1)\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Target variable\n",
    "y = df_bonus['antiguedad']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (optional but can help with model performance)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4806d18d-8649-4568-86c9-8c4d6560864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mq/vcvt6mq97_g4g_xrl4khtv4w0000gn/T/ipykernel_33081/2616995998.py:17: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  imagine = pd.read_csv(path2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "fecha_dato\n",
      "ncodpers\n",
      "ind_empleado\n",
      "pais_residencia\n",
      "sexo\n",
      "age\n",
      "fecha_alta\n",
      "ind_nuevo\n",
      "antiguedad\n",
      "indrel\n",
      "ult_fec_cli_1t\n",
      "indrel_1mes\n",
      "tiprel_1mes\n",
      "indresi\n",
      "indext\n",
      "conyuemp\n",
      "canal_entrada\n",
      "indfall\n",
      "tipodom\n",
      "cod_prov\n",
      "nomprov\n",
      "ind_actividad_cliente\n",
      "renta\n",
      "segmento\n",
      "ind_ahor_fin_ult1\n",
      "ind_aval_fin_ult1\n",
      "ind_cco_fin_ult1\n",
      "ind_cder_fin_ult1\n",
      "ind_cno_fin_ult1\n",
      "ind_ctju_fin_ult1\n",
      "ind_ctma_fin_ult1\n",
      "ind_ctop_fin_ult1\n",
      "ind_ctpp_fin_ult1\n",
      "ind_deco_fin_ult1\n",
      "ind_deme_fin_ult1\n",
      "ind_dela_fin_ult1\n",
      "ind_ecue_fin_ult1\n",
      "ind_fond_fin_ult1\n",
      "ind_hip_fin_ult1\n",
      "ind_plan_fin_ult1\n",
      "ind_pres_fin_ult1\n",
      "ind_reca_fin_ult1\n",
      "ind_tjcr_fin_ult1\n",
      "ind_valo_fin_ult1\n",
      "ind_viv_fin_ult1\n",
      "ind_nomina_ult1\n",
      "ind_nom_pens_ult1\n",
      "ind_recibo_ult1\n",
      "File Size: 2.14 GB\n",
      "Selected Columns:\n",
      "          age antiguedad indrel_1mes conyuemp\n",
      "0          35          6         1.0      NaN\n",
      "1          23         35         1.0      NaN\n",
      "2          23         35         1.0      NaN\n",
      "3          22         35         1.0      NaN\n",
      "4          23         35         1.0      NaN\n",
      "...       ...        ...         ...      ...\n",
      "13647304   22         33           1      NaN\n",
      "13647305   23         33           1      NaN\n",
      "13647306   47         33           1      NaN\n",
      "13647307   22         33         1.0      NaN\n",
      "13647308   37          0         NaN      NaN\n",
      "\n",
      "[13647309 rows x 4 columns]\n",
      "\n",
      "Age Range Counts:\n",
      "18-25: 3854440\n",
      "26-40: 3318957\n",
      "41-65: 5065353\n",
      "66-75: 693937\n",
      "76-100: 555223\n",
      "\n",
      "Mean Income (renta) of Numeric Values: 134087.87\n",
      "Median Income (renta) of Numeric Values: 101490.51\n",
      "\n",
      "Female (sexo = 'V'): 504515 rows\n",
      "Male (sexo = 'H'): 425095 rows\n"
     ]
    }
   ],
   "source": [
    "#Train.csv is a data file\n",
    "path2 = working_directory + '/Downloads/Cross-Selling/Train.csv'\n",
    "\n",
    "# Get the file size in bytes\n",
    "file_size_bytes = os.path.getsize(path2)\n",
    "\n",
    "# Convert file size to a human-readable format (e.g., KB, MB, GB)\n",
    "def convert_bytes(byte_size):\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if byte_size < 1024.0:\n",
    "            return f\"{byte_size:.2f} {unit}\"\n",
    "        byte_size /= 1024.0\n",
    "\n",
    "file_size_readable = convert_bytes(file_size_bytes)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "imagine = pd.read_csv(path2)\n",
    "\n",
    "# Print the names of all columns in the DataFrame\n",
    "print(\"\\nColumn Names:\")\n",
    "for column_name in imagine.columns:\n",
    "    print(column_name)\n",
    "\n",
    "# Convert the 'age' column to numeric (integers), setting non-convertible values to NaN\n",
    "imagine['age'] = pd.to_numeric(imagine['age'], errors='coerce').astype(pd.Int64Dtype())\n",
    "\n",
    "# Display the file size and the first few rows of the DataFrame\n",
    "print(f\"File Size: {file_size_readable}\")\n",
    "\n",
    "# Print specific columns (5, 8, 11, 15)\n",
    "selected_columns = imagine.iloc[:, [5, 8, 11, 15]]\n",
    "print(\"Selected Columns:\")\n",
    "print(selected_columns)\n",
    "\n",
    "# Create age ranges\n",
    "age_ranges = [(18, 25), (26, 40), (41, 65), (66, 75), (76, 100)]\n",
    "\n",
    "# Initialize a dictionary to store counts for each age range\n",
    "age_range_counts = {f\"{start}-{end}\": 0 for start, end in age_ranges}\n",
    "\n",
    "# Count the number of occurrences in each age range\n",
    "for start, end in age_ranges:\n",
    "    age_range_counts[f\"{start}-{end}\"] = len(imagine[(imagine['age'] >= start) & (imagine['age'] <= end)])\n",
    "\n",
    "# Display the counts for each age range\n",
    "print(\"\\nAge Range Counts:\")\n",
    "for age_range, count in age_range_counts.items():\n",
    "    print(f\"{age_range}: {count}\")\n",
    "\n",
    "# Calculate and display the mean and median income (renta) considering only numeric values\n",
    "numeric_renta = pd.to_numeric(df_bonus['renta'], errors='coerce')\n",
    "numeric_renta = numeric_renta.dropna()  # Remove NaN values\n",
    "\n",
    "mean_income = numeric_renta.mean()\n",
    "median_income = numeric_renta.median()\n",
    "\n",
    "print(f\"\\nMean Income (renta) of Numeric Values: {mean_income:.2f}\")\n",
    "print(f\"Median Income (renta) of Numeric Values: {median_income:.2f}\")\n",
    "\n",
    "# Count occurrences where 'sexo' is 'V' (female) and 'H' (male)\n",
    "female_count = df_bonus[df_bonus['sexo'] == 'V']['sexo'].count()\n",
    "male_count = df_bonus[df_bonus['sexo'] == 'H']['sexo'].count()\n",
    "\n",
    "print(f\"\\nFemale (sexo = 'V'): {female_count} rows\")\n",
    "print(f\"Male (sexo = 'H'): {male_count} rows\")\n",
    "\n",
    "# Calculate and display the mean and median age for 'V' (female) and 'H' (male)\n",
    "female_mean_age = df_bonus[df_bonus['sexo'] == 'V']['age'].mean()\n",
    "male_mean_age = df_bonus[df_bonus['sexo'] == 'H']['age'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003a8c8-6fa8-4545-90f1-e10493327ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
