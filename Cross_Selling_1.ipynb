{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0e7307-4e82-4193-8116-c443c1a07203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kuzmauchiha\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "working_directory = os.getcwd()\n",
    "print(working_directory)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8bcdb-4558-44e2-8ea4-b452327fb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mq/vcvt6mq97_g4g_xrl4khtv4w0000gn/T/ipykernel_19979/2715705207.py:20: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_bonus = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year Range Counts:\n",
      "1995-2000: 0\n",
      "2001-2012: 0\n",
      "2013-2018: 929615\n",
      "\n",
      "Oldest Year in 'year': 2016\n",
      "Newest Year in 'year': 2016\n",
      "\n",
      "Common Province Names in 'nomprov' Column:\n",
      "nomprov\n",
      "MADRID                    298250\n",
      "BARCELONA                  88579\n",
      "VALENCIA                   47996\n",
      "SEVILLA                    40492\n",
      "CORUÃ‘A, A                  28715\n",
      "MURCIA                     27752\n",
      "MALAGA                     24546\n",
      "ZARAGOZA                   23160\n",
      "ALICANTE                   22147\n",
      "CADIZ                      19795\n",
      "PONTEVEDRA                 18961\n",
      "ASTURIAS                   18300\n",
      "PALMAS, LAS                16332\n",
      "VALLADOLID                 16018\n",
      "BADAJOZ                    12936\n",
      "TOLEDO                     12658\n",
      "BIZKAIA                    12494\n",
      "GRANADA                    12392\n",
      "SALAMANCA                  11071\n",
      "CANTABRIA                  10824\n",
      "CORDOBA                     9831\n",
      "BALEARS, ILLES              9130\n",
      "CACERES                     8598\n",
      "CIUDAD REAL                 8075\n",
      "HUELVA                      8018\n",
      "ALBACETE                    7780\n",
      "TARRAGONA                   7631\n",
      "CASTELLON                   7145\n",
      "BURGOS                      6645\n",
      "GIRONA                      6304\n",
      "NAVARRA                     6010\n",
      "RIOJA, LA                   5806\n",
      "LEON                        5717\n",
      "LUGO                        5656\n",
      "OURENSE                     5605\n",
      "LERIDA                      5430\n",
      "SANTA CRUZ DE TENERIFE      5097\n",
      "GIPUZKOA                    4869\n",
      "GUADALAJARA                 4678\n",
      "JAEN                        4496\n",
      "ALMERIA                     4307\n",
      "CUENCA                      3788\n",
      "ZAMORA                      3430\n",
      "PALENCIA                    3311\n",
      "SEGOVIA                     2881\n",
      "HUESCA                      2789\n",
      "AVILA                       2628\n",
      "ALAVA                       2591\n",
      "TERUEL                      1538\n",
      "SORIA                       1261\n",
      "MELILLA                      643\n",
      "CEUTA                        513\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to 'Test.csv'\n",
    "path = working_directory + '/Downloads/Cross-Selling/Test.csv'\n",
    "\n",
    "# Get the file size in bytes\n",
    "file_size_bytes = os.path.getsize(path)\n",
    "\n",
    "# Convert file size to a human-readable format (e.g., KB, MB, GB)\n",
    "def convert_bytes(byte_size):\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if byte_size < 1024.0:\n",
    "            return f\"{byte_size:.2f} {unit}\"\n",
    "        byte_size /= 1024.0\n",
    "\n",
    "file_size_readable = convert_bytes(file_size_bytes)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_bonus = pd.read_csv(path)\n",
    "\n",
    "# Data exploration code (Age, Canal_Entrada, Ind_Nuevo, Sexo, etc.)\n",
    "\n",
    "# Convert 'fecha_dato' to a datetime data type\n",
    "df_bonus['fecha_dato'] = pd.to_datetime(df_bonus['fecha_dato'])\n",
    "\n",
    "# Extract the year from 'fecha_dato' and store it as a new column\n",
    "df_bonus['year'] = df_bonus['fecha_dato'].dt.year\n",
    "\n",
    "# Create year ranges based on the new 'year' column\n",
    "year_ranges = [(1995, 2000), (2001, 2012), (2013, 2018)]\n",
    "\n",
    "# Initialize a dictionary to store counts for each year range\n",
    "year_range_counts = {f\"{start}-{end}\": 0 for start, end in year_ranges}\n",
    "\n",
    "# Extract the year from the 'year' column and count occurrences in each year range\n",
    "for start, end in year_ranges:\n",
    "    year_range_counts[f\"{start}-{end}\"] = len(df_bonus[(df_bonus['year'] >= start) & (df_bonus['year'] <= end)])\n",
    "\n",
    "# Display the counts for each year range\n",
    "print(\"\\nYear Range Counts:\")\n",
    "for year_range, count in year_range_counts.items():\n",
    "    print(f\"{year_range}: {count}\")\n",
    "\n",
    "# Find the oldest and newest year in the 'year' column\n",
    "oldest_year = df_bonus['year'].min()\n",
    "newest_year = df_bonus['year'].max()\n",
    "\n",
    "print(f\"\\nOldest Year in 'year': {oldest_year}\")\n",
    "print(f\"Newest Year in 'year': {newest_year}\")\n",
    "\n",
    "# Count and display common province names in the 'nomprov' column\n",
    "province_counts = df_bonus['nomprov'].value_counts()\n",
    "\n",
    "print(\"\\nCommon Province Names in 'nomprov' Column:\")\n",
    "print(province_counts)\n",
    "\n",
    "# Machine learning code\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define 'X' (feature matrix) and 'y' (target variable)\n",
    "# Exclude non-numeric columns and any other columns that should not be used as features\n",
    "exclude_columns = ['antiguedad', 'fecha_dato', 'year']\n",
    "X = df_bonus.drop(exclude_columns, axis=1)\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Target variable\n",
    "y = df_bonus['antiguedad']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (optional but can help with model performance)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4806d18d-8649-4568-86c9-8c4d6560864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mq/vcvt6mq97_g4g_xrl4khtv4w0000gn/T/ipykernel_32166/1024780923.py:12: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  imagine = pd.read_csv(path2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'sexo' column does not exist in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os  # Add this import\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "path2 = working_directory + '/Downloads/Cross-Selling/Train.csv'\n",
    "imagine = pd.read_csv(path2)\n",
    "\n",
    "# Identify and exclude non-numeric columns\n",
    "non_numeric_columns = imagine.select_dtypes(exclude=[np.number]).columns\n",
    "imagine = imagine.drop(columns=non_numeric_columns)\n",
    "\n",
    "# Use a SimpleImputer to fill in missing values in the entire DataFrame\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imagine = pd.DataFrame(imputer.fit_transform(imagine), columns=imagine.columns)\n",
    "\n",
    "# Check if 'sexo' exists in the DataFrame\n",
    "if 'sexo' in imagine.columns:\n",
    "    # Print the names of all columns in the DataFrame\n",
    "    print(\"\\nColumn Names:\")\n",
    "    for column_name in imagine.columns:\n",
    "        print(column_name)\n",
    "\n",
    "    # Display the file size and the first few rows of the DataFrame\n",
    "    file_size_bytes = os.path.getsize(path2)\n",
    "    file_size_readable = convert_bytes(file_size_bytes)\n",
    "\n",
    "    print(f\"File Size: {file_size_readable}\")\n",
    "\n",
    "    # Print specific columns (5, 8, 11, 15)\n",
    "    selected_columns = imagine.iloc[:, [5, 8, 11, 15]]\n",
    "    print(\"Selected Columns:\")\n",
    "    print(selected_columns)\n",
    "\n",
    "    # Calculate and display the mean and median income (renta) considering only numeric values\n",
    "    numeric_renta = pd.to_numeric(imagine['renta'], errors='coerce')\n",
    "    mean_income = numeric_renta.mean()\n",
    "    median_income = numeric_renta.median()\n",
    "\n",
    "    print(f\"\\nMean Income (renta) of Numeric Values: {mean_income:.2f}\")\n",
    "    print(f\"Median Income (renta) of Numeric Values: {median_income:.2f}\")\n",
    "\n",
    "    # Count occurrences where 'sexo' is 'V' (female) and 'H' (male)\n",
    "    female_count = imagine[imagine['sexo'] == 'V']['sexo'].count()\n",
    "    male_count = imagine[imagine['sexo'] == 'H']['sexo'].count()\n",
    "\n",
    "    print(f\"\\nFemale (sexo = 'V'): {female_count} rows\")\n",
    "    print(f\"Male (sexo = 'H'): {male_count} rows\")\n",
    "\n",
    "    # Define the features (X) and target variable (y)\n",
    "    X = imagine[['ind_actividad_cliente', 'renta']]  # Use relevant features\n",
    "    y = imagine['sexo']  # Assuming 'sexo' is the target variable\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    # Split the data into a training set and a testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize the SVM model\n",
    "    svm_model = SVC()\n",
    "\n",
    "    # Train the model on the training data\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    classification = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification)\n",
    "else:\n",
    "    print(\"The 'sexo' column does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003a8c8-6fa8-4545-90f1-e10493327ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
